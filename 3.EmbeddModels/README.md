# ğŸ§© LangChain Embedding Models

This folder contains **hands-on examples of text embeddings** using **LangChain** with multiple providers including  
**OpenAI, Google Gemini, and Hugging Face**, along with a practical **document similarity use case**.

The examples demonstrate how raw text is converted into **numerical vectors** and how those vectors are used in
real-world GenAI workflows like **semantic search, similarity matching, and retrieval systems**.

---

## ğŸš€ About Embeddings

**Embeddings** transform text into high-dimensional numerical vectors that capture semantic meaning.

They are the backbone of:
- ğŸ” Semantic Search  
- ğŸ“„ Document Similarity  
- ğŸ§  Retrieval-Augmented Generation (RAG)  
- ğŸ¤– Recommendation Systems  
- ğŸ“š Knowledge Bases  

This folder focuses on **query embeddings**, **document embeddings**, and **similarity scoring**.

---

## ğŸ“‚ Folder Structure

```bash
ğŸ“ EmbeddingModels
â”‚
â”œâ”€â”€ 1_embedding_openai_query.py      # OpenAI query embedding
â”œâ”€â”€ 2_embedding_openai_docs.py       # OpenAI document embeddings
â”œâ”€â”€ 3_embedding_gemini.py            # Google Gemini embeddings
â”œâ”€â”€ 4_embedding_hf_query.py          # Hugging Face query embedding
â”œâ”€â”€ 5_embedding_hf_docs.py           # Hugging Face document embeddings
â”œâ”€â”€ 6_document_similarity.py         # Document similarity using cosine similarity
â””â”€â”€ README.md
```

---

## ğŸ“„ File-wise Explanation
ğŸ”¹ 1_embedding_openai_query.py
- Uses OpenAIEmbeddings
- Generates embedding for a single query
- Uses text-embedding-3-large
- Demonstrates reduced embedding dimensions

Use case:
- Query encoding for semantic search
- RAG query vector creation

ğŸ”¹ 2_embedding_openai_docs.py
- Uses OpenAIEmbeddings
- Generates embeddings for multiple documents
- Demonstrates batch document embedding

Use case:
- Vector database ingestion
- Knowledge base indexing

ğŸ”¹ 3_embedding_gemini.py

- Uses GoogleGenerativeAIEmbeddings
- Integrates Google Gemini embedding model
- Converts text into dense semantic vectors

Use case:
- Google ecosystem-based GenAI pipelines
- Lightweight embedding generation

ğŸ”¹ 4_embedding_hf_query.py

- Uses HuggingFaceEmbeddings
- Model: sentence-transformers/all-MiniLM-L6-v2
- Generates embedding for a single query
- Fully open-source

Use case:
- Cost-free embedding experiments
- Offline / open-source workflows

ğŸ”¹ 5_embedding_hf_docs.py

- Uses HuggingFaceEmbeddings
- Generates embeddings for multiple documents
- Uses sentence-transformers

Use case:
- Local semantic search
- Vector store preparation without APIs

ğŸ”¹ 6_document_similarity.py

- Uses Hugging Face embeddings
- Computes cosine similarity
- Finds the most relevant document for a query
- Uses real-world text examples

Use case:
- Document matching
- FAQ retrieval
- Resume / profile similarity
- Search ranking logic

---

## ğŸ§  Key Concepts Covered
- Query vs Document embeddings
- Vector representations of text
- Cosine similarity scoring
- API-based vs Local embeddings
- Provider comparison (OpenAI vs Gemini vs Hugging Face)
- Core foundation for RAG systems

---

## ğŸ§  When to Use Which Provider?
| Provider     | Best For                               |
| ------------ | -------------------------------------- |
| OpenAI       | High-quality production embeddings     |
| Gemini       | Google-centric GenAI pipelines         |
| Hugging Face | Open-source, local, cost-free learning |

---

## ğŸ‘¨â€ğŸ’» Author

Manthan Jadav
AI / ML & GenAI Enthusiast

ğŸ”— GitHub: https://github.com/Manthan2110

ğŸ”— LinkedIn: https://www.linkedin.com/in/manthanjadav/
