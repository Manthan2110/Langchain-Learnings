# ğŸ§  LangChain LLM Demo (Google Gemini)

A simple, beginner-friendly demonstration of using a **Large Language Model (LLM)** with **LangChain**, powered by **Google Gemini**.

This example focuses on **basic LLM invocation** (not chat models) to help understand how LangChain interacts with foundation models at a low level.

---

## ğŸš€ About This Example

This script demonstrates:
- How to initialize an **LLM (not ChatModel)** in LangChain
- How to connect **Google Gemini** using an API key
- How to invoke the model with a prompt
- How LLMs differ from chat-based models in LangChain

This is ideal for learners starting their **GenAI / LangChain journey**.

---

## ğŸ“‚ File Overview

```bash
ğŸ“ 1.LLMs
â”‚
â”œâ”€â”€ 1_llm_demo.py
â””â”€â”€ README.md
```

---

## ğŸ“„ File Explanation

> 1_llm_demo.py
- Uses GoogleGenerativeAI from LangChain
- Integrates Google Gemini (gemini-2.5-flash)
- Demonstrates basic prompt â†’ response workflow
- Uses .invoke() to get a raw LLM output

> Example task:
Asking a factual question: â€œWho is the Prime Minister of India now?â€

---

## ğŸ§  Key Concepts Covered

- What is an LLM in LangChain
- Difference between:
  - LLM (single-turn text generation)
  - ChatModel (role-based conversations)
- Prompt execution using .invoke()
- Model selection and configuration

--- 

## ğŸ¯ Use Cases

- Learning LangChain fundamentals
- Understanding LLM vs ChatModel
- Quick factual queries
- Lightweight GenAI experiments

---

## ğŸ‘¨â€ğŸ’» Author

Manthan Jadav
AI / ML & GenAI Enthusiast

ğŸ”— GitHub: https://github.com/Manthan2110

ğŸ”— LinkedIn: https://www.linkedin.com/in/manthanjadav/

---

â­ If this helped you understand LangChain basics, consider starring the repository!
